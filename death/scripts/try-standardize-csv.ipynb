{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "import pandas as pd\n",
    "from distutils.util import strtobool\n",
    "\n",
    "# スクリプトへエクスポートした際に、必要に応じてパスの更新が必要な情報\n",
    "csv_folder = os.path.join('..', 'intermediate-files')\n",
    "csv_file_name = '001320852-pre.csv' # sys.argv[1]\n",
    "manufacturer = 'ファイザー' # sys.argv[2]\n",
    "vaccine_name = 'コミナティRTU筋注（1価：オミクロン株XBB.1.5）' # sys.argv[3]\n",
    "has_vaccinated_times = bool(strtobool('false')) # sys.argv[4]\n",
    "\n",
    "csv_file_path = os.path.join(csv_folder, csv_file_name)\n",
    "original_df = pd.read_csv(csv_file_path, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 列の調整。PDFから読み取った内容によっては列の数などが変動して、ここの処理を変える必要があるかも。\n",
    "df = original_df.copy()\n",
    "\n",
    "# 「接種回数」の列があるデータの場合、ロット番号の後に追加する\n",
    "if has_vaccinated_times:\n",
    "\tcolumns = ['no', 'age', 'gender', 'vaccinated_date', 'onset_date', 'lot_no', 'vaccinated_times', 'pre_existing_disease_names', 'reported_desc', 'PT_names', 'tests_used_for_determination', 'causal_relationship', 'possible_presence_of_other_factors', 'causal_relationship_by_expert_previous', 'comment_previous', 'causal_relationship_by_expert', 'comment', 'document_no', 'case_no']\n",
    "else:\n",
    "\tcolumns = ['no', 'age', 'gender', 'vaccinated_date', 'onset_date', 'lot_no', 'pre_existing_disease_names', 'reported_desc', 'PT_names', 'tests_used_for_determination', 'causal_relationship', 'possible_presence_of_other_factors', 'causal_relationship_by_expert_previous', 'comment_previous', 'causal_relationship_by_expert', 'comment', 'document_no', 'case_no']\n",
    "df.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No列に値が入った行だけを抽出する。\n",
    "# このインデックスからインデックスの間に、PT_namesのデータが行に分かれて入っているので、マージする。\n",
    "number_df = df[df['no'].notna()]\n",
    "\n",
    "# またnumber_dfのcausal_relationship_by_expert列がNaNになっているデータは、表の形が崩れていて他の\n",
    "# データも後の行に分散してしまっているデータと思われるので、手作業で修正するようログを残す。\n",
    "need_manually_fix_df = number_df[number_df['causal_relationship_by_expert'].isna()]\n",
    "if not need_manually_fix_df.empty:\n",
    "\tfor index, row in need_manually_fix_df.iterrows():\n",
    "\t\tnumber = row['no']\n",
    "\t\tprint(f'Index {index}, No {number} のデータは、後続の行にデータが分散していると思われます。手作業で修正してください。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# マージした行のインデックスを保持して後ほどdrop処理に使う\n",
    "merged_index = []\n",
    "\n",
    "previous_index = 0\n",
    "for index, _ in number_df.iterrows():\n",
    "\tif index == 0: continue\n",
    "\n",
    "\tif previous_index in need_manually_fix_df.index:\n",
    "\t\tprint(f'Index {previous_index} は手作業の対象のためマージ処理をスキップします。')\n",
    "\telif index - 1 > previous_index:\n",
    "\t\t# マージが必要な行が previous_index+1 から index-1 までのインデックスに存在する\n",
    "\t\tpt_names = []\n",
    "\t\tsub_index = previous_index+1\n",
    "\t\twhile sub_index < index:\n",
    "\t\t\tpt_names.append(df.loc[sub_index, 'reported_desc'])\n",
    "\t\t\tmerged_index.append(sub_index)\n",
    "\t\t\tsub_index += 1\n",
    "\t\tnumber_df.at[previous_index, 'PT_names'] = pt_names\n",
    "\telse:\n",
    "\t\t# マージ不要なケース、PT_namesの内容を配列に変更する\n",
    "\t\tpt_name = [ number_df.loc[previous_index, 'PT_names'] ]\n",
    "\t\tnumber_df.at[previous_index, 'PT_names'] = pt_name\n",
    "\n",
    "\tprevious_index = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最後の行も処理する。\n",
    "# previous_indexにはnumber_dfの最後のインデックスが格納された状態でここに来るので、\n",
    "\n",
    "# dfの最後のインデックス。\n",
    "# previous_indexよりもlast_indexの方が大きい数字の場合、マージ処理の要否を確認しながら処理が必要。\n",
    "last_index = df.shape[0] - 1\n",
    "\n",
    "if previous_index in need_manually_fix_df.index:\n",
    "\tprint(f'Index {previous_index} は手作業の対象のためマージ処理をスキップします。')\n",
    "elif last_index > previous_index:\n",
    "\t# マージが必要な行が previous_index+1 から last_index までのインデックスに存在する\n",
    "\tpt_names = []\n",
    "\tsub_index = previous_index+1\n",
    "\twhile sub_index <= last_index:\n",
    "\t\tpt_names.append(df.loc[sub_index, 'reported_desc'])\n",
    "\t\tmerged_index.append(sub_index)\n",
    "\t\tsub_index += 1\n",
    "\tnumber_df.at[previous_index, 'PT_names'] = pt_names\n",
    "else:\n",
    "\t# マージ不要なケース、PT_namesの内容を配列に変更する\n",
    "\tpt_name = [ number_df.loc[previous_index, 'PT_names'] ]\n",
    "\tnumber_df.at[previous_index, 'PT_names'] = pt_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 元の症例一覧には製造販売業者やワクチン名が記載されていないので、引数でもらった情報を使って列を追加する\n",
    "# PT_names列以外のデータ有無によって処理を分けている箇所があるため、この列挿入は最後に行う必要がある。\n",
    "df.insert(1, column='manufacturer', value=manufacturer)\n",
    "df.insert(2, column='vaccine_name', value=vaccine_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_df = df.drop(merged_index)\n",
    "fixed_df['no'] = fixed_df['no'].fillna(-1)\n",
    "fixed_df.loc[number_df.index, 'no'] = number_df['no']\n",
    "fixed_df['no'] = fixed_df['no'].astype(int)\n",
    "fixed_df.loc[number_df.index, 'PT_names'] = number_df['PT_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_name_without_ext = os.path.splitext(csv_file_name)[0].replace('-pre', '-converted')\n",
    "csv_file_path = os.path.join(csv_folder, f'{csv_file_name_without_ext}.csv')\n",
    "with open(csv_file_path, encoding='utf-8', mode='w') as f:\n",
    "\tf.write(fixed_df.to_csv(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_empty_lines(source_path, target_path):\n",
    "    fixed_data = ''\n",
    "    with open(source_path, encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if line.isspace():\n",
    "                continue\n",
    "            if line.startswith('0,1,2,3,4,5'):\n",
    "                continue\n",
    "            if line.startswith(','):\n",
    "                line = re.sub('^,', '', line)\n",
    "            fixed_data += line\n",
    "\n",
    "    with open(target_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(fixed_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_empty_lines(csv_file_path, csv_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
